公用类库

为项目的公共实现，提供服务，单不提供具体的实现

批量作业的实现见：smlbatch
流式作业的实现见：pipeline

包括以下模块

## 配置

以数据方式保存，包括以下配置：
1. 运行时的任务参数(key-value模式)
   - 系统参数
   - spark运行设定
2. 输入
   - 输入目标
   - 输入参数
3. 处理器
   - 处理器名字
   - 处理器版本(考虑包含在处理器名字中)
   - 处理器参数(key-value模式)
4. 输出
   - 输出目标
   - 输出参数

## 插件机制

1. 可扩展的机制(系统级，考虑动态载入)
   - 输入
   - 输出
   - 处理器
2. 处理器实现，通过spark udf进行扩展
3. 输入/输出是通过spark生态的支持，手动编码实现
